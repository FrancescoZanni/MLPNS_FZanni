{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpGSA6Dkkpyhq0t803DmBh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoZanni/MLPNS_FZanni/blob/main/MLPNS_Week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lezione 10\n",
        "##fine del GRB\n"
      ],
      "metadata": {
        "id": "XbnI7Ubq5TU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Likelihood ratio test: \n",
        "Torno in ambito null hrt\n",
        "-2log(likelihood(modello complesso)/likelihood(modello semplice)\n",
        "dovrebbe essere distribuita con chi quadro, così posso vedere quale modello è piu semplice e scegliere in base al rasoio di Occam \n",
        "\n",
        "potrei implementare\n",
        "\n",
        "La frazione, che avrà sempre un valore maggiore di 1 perche più parametri da migliore likelihood, è abbastanza grande da giustificare l'aumento di parametri?\n",
        "\n",
        "è distr come uñchi sq distr, che ha come degrees of freedom la DIFFERENZA DEL NUMERO DI PARAMETRI \n",
        "\n",
        "una volta calcolato il valore vado nei valori critici della chi sq distr e controllo il pvalue confrontandolo al numero di sigma scelto in anticipo\n",
        "\n",
        "\n",
        "###Altri modelli: \n",
        "- AIC: si basa sulla stat frequentistica\n",
        "- BIC: si basa sul bayes theorem\n",
        "- MLD (minimum description lenght): si basa sul signal processing e information theory\n",
        "\n",
        "quasi tutti iguali con piccole differenze: tutti contengono una metrica delle performance del modello (likelihood) e una misura della complessità (numero di parametri)\n",
        "\n",
        "Li mettono insieme in modi diversi:\n",
        "- AIC ha un pezzo negativo, cioè che diminuisce per modelli miglpiori e un pezzo che cresce con la complessità del modelli, il goal è di ottenere un valore piccolo\n",
        "- BIC quasi uguale ma derivazione diversa, costanti differenti e la complessità del modello netra in due modi, anche il numero delle variabili.\n",
        "- MDL stesso principio, deriva dal bayes th, non importa tanto la formula, chissene della derivazione\n",
        "\n",
        "\n",
        "IMPLEMENTAZIONE (link nelle slide)\n",
        "\n",
        "###Come li utilizzo\n",
        "in generale cerco il valore per il quale sono minimizzati, ma non sempre sono minimizzati per lo stesso valore, potrei avere modelli preferiti diversi in base al test che ho scelto!\n",
        "\n",
        "L'utilizzo più appropriato è vedere quando la curva si stabilizza, cioè quando smette di scendere velocemente, e in quel caso dovrebbero dare lo stesso risultato. \n",
        "\n"
      ],
      "metadata": {
        "id": "MgF7O7Fm2C2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Unsipervised learning e clustering\n",
        "\n",
        "problema del clustering, si divide in 3 categorie\n",
        "- partitioning\n",
        "- density based clustering\n",
        "- hierarcical clustering\n",
        "\n",
        "se ho unsupervised non ho una variabile relazionata ai dati, \n",
        "voglio creare una nuova variabile che metto in relazione al featire space\n",
        "Per la maggior parte dei modelli diventa abbastanza ovvio, in neural nets sono tuttu supervised che si possono utilizzare per i goal dell'unsipervised learning: \n",
        "Voglio riprodurre una variabile che conosco o voglio creare una nuova variabile\n",
        "\n",
        "Motivo per l'unsipervised: voglio capire se ci sono relazioni fra i dati, per esempio se ho dati generati dallo stesso fenomeno oppure generati da fenomeni differenti\n",
        "\n",
        "oppure se posso trovare una descrizione dei dati che è meno dettagliata ma ugualmente soddisfacente: dimensionality reduction\n",
        "\n",
        "posso vedere se ci sono dei dati che sono particolarmente isolati:\n",
        "unsupervised learning enables anomaly detection!\n",
        "\n",
        "##modelli\n",
        "- PCS principal component analysis\n",
        "- Apriori\n",
        "- Clustering: il principale di cui ci occupiamo\n",
        "\n",
        "\n",
        "criteri per il clustering:\n",
        "-Criterio interno: membri dello stesso gruppo devono essere simili (compattezza del cluster: area piccola)\n",
        "-Criterio esterno: membri di gruppi diversi devono essere diversi (distanza dei cluster grande)\n",
        "\n",
        "Cose a cui devo pensare: \n",
        "- fra tutte le variabili che ho quali usare e come prepararle\n",
        "- come definisco la distanza\n",
        "- quale algoritmo utilizzare (dipenderà dalla distanza che ho scelto, non tutti gli algoritmi per tutte le distanze)\n",
        "\n",
        "OSS: per certi algoritmi il numero di cluster è un hyperparameter!! devo fare una guess e vedere se ottimale ecc.\n",
        "\n",
        "ideal algorithm fearures: VEDI SLIDE\n",
        "\n",
        "##DISTANCE METRICS\n",
        "(tutte le loss functions che usiamo sono sempre distanze)\n",
        "Famiglio di Minkowski: funziona se le variabili sono tutte numeriche, sono le varie Li\n",
        "\n",
        "4 regole per le distanze, vedi slide ma sone le solite\n",
        "unexpected \"ci sono distanze negative in altri spazi\", maggiore di 0 vale solo per la famiglia di mink...\n",
        "\n",
        "La metrica di Mink si attiene a tutte e 4\n",
        "\n",
        "L1: Manhattan distance (perchè a grid di strade perpendicolare)\n",
        "L2: distanza aerea, metrica euclidea\n",
        "\n",
        "OSS: la scelta della metrica è un hyperparameter!\n",
        "\n",
        "Le cose si complicano se ho bisogno di definire distanze in presenza di varaibili categoriche (\"Distanza fra un falco e una tigre\")\n",
        "\n",
        "Copresenza o coassenza di variabili binarie categoriche, per es presenza o no della coda o del becco, faccio la tabella di verità e mi da la distanza, poi posso farlo con n variabili categoriche binarie, la distanza è ricavata dalla tabella e ci sono vari metodi: \n",
        "\n",
        "- simple matching coefficient\n",
        "- jaccard similarity\n",
        "\n",
        "ecc.\n",
        "\n",
        "Esempio importante: \n",
        "applicazione più diretta: la jaccard similaruty è utilizzata in comp vision per definire la performance di un neural net che identifica la presenza di oggetti, cerca overlap, vedi slide ok  (\"intersection over union\")\n",
        "\n",
        "In questo caso la loss function sarà una jaccard similarity\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X07QAmSl5Q5F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73cJuhOWp3BD"
      },
      "outputs": [],
      "source": []
    }
  ]
}